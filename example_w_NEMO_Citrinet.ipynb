{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3B0i9Tlaa2T",
    "tags": []
   },
   "source": [
    "# Long-form audio transcription using Citrinet\n",
    "Modified from:\n",
    "- https://colab.research.google.com/gist/titu1994/a44fffd459236988ee52079ff8be1d2e/long-audio-transcription-citrinet.ipynb?pli=1#scrollTo=rZITgro3DC_v\n",
    "- https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/asr/models.html\n",
    "- [Citrinet: Closing the Gap between Non-Autoregressive and Autoregressive End-to-End Models for Automatic Speech Recognition](https://arxiv.org/abs/2104.01721)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Long-form audio transcription is an interesting application of ASR. Generally, models are trained on short segments of 15-20 seconds of audio clips. If an ASR model is compatibile with streaming inference, it can then be evaluated on audio clips much longer than the training duration.\n",
    "\n",
    "> Generally, streaming inference will incur a small increase in WER due to loss of long term context. Think of it as this - if a streaming model has a context window of a few seconds of audio, even if it streams several minute long audio clips - later transcriptions have lost some of prior context.\n",
    "\n",
    "> In this demo, we consider the naive case of long-form audio transcription, asking the question - in the offline mode (i.e. when the model is given the entire audio sequence at once), what is maximum duration of audio that it can transcribe?\n",
    "\n",
    "> For the purposes of this demo, we will test the limits of Citrinet models [(arxiv)](https://arxiv.org/abs/2104.01721), which are purely convolutional ASR models.\n",
    "\n",
    "> Unlike general attention based models, convolutional models don't have a quadratic cost to their context window, but they also miss out on global context offered by the attention mechanism. Citrinet instead attains relatively long context by replacing attention with [Squeeze-and-Excitation modules](https://arxiv.org/abs/1709.01507) between its blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install NeMo\n",
    "- https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/starthere/intro.html#installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get update && apt-get install -y libsndfile1 ffmpeg\n",
    "# !pip install Cython\n",
    "# !pip install nemo_toolkit[all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BRANCH = 'main'\n",
    "# !python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH #egg=nemo_toolkit[all]\n",
    "# !pip install inflect\n",
    "# print(\"Finished installing nemo !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2021-12-15 13:24:07 optimizers:50] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2021-12-15 13:24:07 experimental:27] Module <function get_argmin_mat at 0x7fc3afacc160> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2021-12-15 13:24:07 experimental:27] Module <function getMultiScaleCosAffinityMatrix at 0x7fc3afacc1f0> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2021-12-15 13:24:07 experimental:27] Module <function parse_scale_configs at 0x7fc3afaccd30> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2021-12-15 13:24:07 experimental:27] Module <function get_embs_and_timestamps at 0x7fc3afaccdc0> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nemo.collections.asr as nemo_asr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gm13VSJ9FDc0",
    "tags": []
   },
   "source": [
    "## Download audio from YouTube\n",
    "\n",
    "> In order to make the task slightly more difficult, we will attempt to transcribe an entire podcast at once. \n",
    "\n",
    "> Why a podcast? Podcasts are generally long verbal discussions between one or more people on a specific topic, the domain of discussion is unlikely to match the model's training corpus (unless the training corpus is vast), and possibly inclue background audio or sponsorship information in between the discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UpkxNg3kyLG"
   },
   "source": [
    "**Below, please give your permission to download the audio clip and the transcript from the Screaming in the Cloud podcast mentioned above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ffmpeg-python\n",
    "# !pip install ffmpeg\n",
    "# !pip install ffprobe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists as path_exists\n",
    "\n",
    "if not path_exists('transcripts'):\n",
    "    !mkdir transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeID = 'gFFLJaQbLCM' \n",
    "OutputFile = 'test_audio_youtube.m4a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] ns42RRd9BIg: Downloading webpage\n",
      "[download] data/raw_audio.mp3 has already been downloaded\n",
      "\u001b[K[download] 100% of 12.27MiB\n",
      "[ffmpeg] Post-process file data/raw_audio.mp3 exists, skipping\n"
     ]
    }
   ],
   "source": [
    "if not path_exists(OutputFile):\n",
    "    !youtube-dl -o $OutputFile $YouTubeID --extract-audio --restrict-filenames -f 'bestaudio[ext=m4a]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrn6ggIVG0vF"
   },
   "source": [
    "## Preprocess Audio\n",
    "\n",
    "> We now have the raw audio file (in mp3 format) from the podcast. To make this audio file compatible with the model (monochannel, 16 KHz audio), we will use FFMPEG to preprocess this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fNwVEWhxGJ9j"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob \n",
    "import subprocess\n",
    "\n",
    "def transcode(input_dir, output_format, sample_rate, skip, duration):\n",
    "    files = glob.glob(os.path.join(input_dir, \"*.*\"))\n",
    "\n",
    "    # Filter out additional directories\n",
    "    files = [f for f in files if not os.path.isdir(f)]\n",
    "\n",
    "    output_dir = os.path.join(input_dir, \"processed\")\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        print(f\"Output directory {output_dir} does not exist, creating ...\")\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filepath in files:\n",
    "        output_filename = os.path.basename(filepath)\n",
    "        output_filename = os.path.splitext(output_filename)[0]\n",
    "\n",
    "        output_filename = f\"{output_filename}_processed.{output_format}\"\n",
    "\n",
    "        args = [\n",
    "            'ffmpeg',\n",
    "            '-i',\n",
    "            str(filepath),\n",
    "            '-ar',\n",
    "            str(sample_rate),\n",
    "            '-ac',\n",
    "            str(1),\n",
    "            '-y'\n",
    "        ]\n",
    "\n",
    "        if skip is not None:\n",
    "            args.extend(['-ss', str(skip)])\n",
    "\n",
    "        if duration is not None:\n",
    "            args.extend(['-to', str(duration)])\n",
    "\n",
    "        args.append(os.path.join(output_dir, output_filename))\n",
    "        command = \" \".join(args)\n",
    "        !{command}\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(f\"Finished trancoding {len(files)} audio files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Q6WlUUKoHCNw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.4.0 (GCC)\n",
      "  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1636205340875/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1636205340875/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-demuxer=dash --enable-gnutls --enable-gpl --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-vaapi --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-libvpx --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1636205340875/_build_env/bin/pkg-config\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, matroska,webm, from './data/raw_audio.mp3':\n",
      "  Metadata:\n",
      "    encoder         : google/video-file\n",
      "  Duration: 00:12:36.48, start: -0.007000, bitrate: 136 kb/s\n",
      "  Stream #0:0(eng): Audio: opus, 48000 Hz, stereo, fltp (default)\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (opus (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to './data/processed/raw_audio_processed.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf58.76.100\n",
      "  Stream #0:0(eng): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 pcm_s16le\n",
      "size=   23639kB time=00:12:36.46 bitrate= 256.0kbits/s speed= 280x    \n",
      "video:0kB audio:23639kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000322%\n",
      "\n",
      "\n",
      "Finished trancoding 1 audio files\n"
     ]
    }
   ],
   "source": [
    "transcode(\n",
    "        input_dir=\"./data/\",\n",
    "        output_format=\"wav\",\n",
    "        sample_rate=16000,\n",
    "        skip=None,\n",
    "        duration=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZlnKflsXvXq"
   },
   "source": [
    "# Transcribe the processed audio file\n",
    "\n",
    "Now that we have a \"ground truth\" text transcript we can compare against, let's actually transcribe the podcast with a model !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXc5NQFcX01v"
   },
   "source": [
    "## Helper methods\n",
    "\n",
    "We define a few helper methods to enable automatic mixed precision if it is available in the colab GPU (if a GPU is being used at all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "19p2X0deX3Ku"
   },
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Adg2CWbqX4Cf"
   },
   "outputs": [],
   "source": [
    "# Helper for torch amp autocast\n",
    "if torch.cuda.is_available():\n",
    "    autocast = torch.cuda.amp.autocast\n",
    "else:\n",
    "    @contextlib.contextmanager\n",
    "    def autocast():\n",
    "        print(\"AMP was not available, using FP32!\")\n",
    "        yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "74bEhFRuX99E"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1u_WXD8IYTpI"
   },
   "source": [
    "## Instantiate a model\n",
    "- https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/asr/results.html\n",
    "\n",
    "We choose a small model - Citrinet 256 - since it offers good transcription accuracy but is just 10 M parameters.\n",
    "\n",
    "**Feel free to change to the medium and larger sized models !**\n",
    "\n",
    " - small = \"stt_en_citrinet_256\" (9.8 M parameters)\n",
    " - medium = \"stt_en_citrinet_512\" (38 M parameters)\n",
    " - large = \"stt_en_citrinet_1024\" (142 M parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = nemo_asr.models.EncDecCTCModel.from_pretrained(\"stt_es_quartznet15x5\", map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Nm-BveGxYNkP"
   },
   "outputs": [],
   "source": [
    "model = nemo_asr.models.EncDecCTCModelBPE.from_pretrained(\"stt_es_citrinet_512\", map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "FoGVootFYqGW"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpndoavWY27v"
   },
   "source": [
    "## Transcribe audio\n",
    "\n",
    "Here, we simply call the model's \"transcribe()\" method, which does offline transcription of a provided list of audio clips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "r7FyeM8BY0Ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, delete transcripts/normalized/transcribed_speech.txt manually before re-transcribing the audio !\n",
      "CPU times: user 519 µs, sys: 185 µs, total: 704 µs\n",
      "Wall time: 451 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "audio_path = \"data/processed/raw_audio_processed.wav\"\n",
    "transcribed_filepath = f\"transcripts/normalized/transcribed_speech.txt\"\n",
    "\n",
    "if os.path.exists(transcribed_filepath):\n",
    "    print(f\"File already exists, delete {transcribed_filepath} manually before re-transcribing the audio !\")\n",
    "\n",
    "else:\n",
    "    with autocast():\n",
    "        transcript = model.transcribe([audio_path], batch_size=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIIiZ6GfZvkM"
   },
   "source": [
    "## Write transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.dirname(transcribed_filepath)):\n",
    "    os.makedirs(os.path.dirname(transcribed_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "UkrDWKSuZD0k"
   },
   "outputs": [],
   "source": [
    "with open(transcribed_filepath, 'w', encoding='utf-8') as f:\n",
    "    f.write(f\"{transcript}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_524/2103537015.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "797I6ITYaK0Y",
    "tags": []
   },
   "source": [
    "# Compute accuracy of transcription\n",
    "\n",
    "Now that we have a model's transcriped result, we compare the WER and CER against the \"ground truth\" transcription that we preprocessed earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "TUueKbEsaaZx"
   },
   "outputs": [],
   "source": [
    "model_transcript = transcribed_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Dsev1XArapUz"
   },
   "outputs": [],
   "source": [
    "with open(model_transcript, 'r') as f:\n",
    "    transcription_txt = f.readlines()\n",
    "    transcription_txt = [text.replace(\"\\n\", \"\") for text in transcription_txt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sois maría esperanza caszúna soy unndrés malhamut y esto es agora ocaste conversación política el diario haz buen día andrés como estás todo la me festejando qué estamos festejando es la democracia no como lo vemos al lo cortemos una oportunidad para pelearnos soy bueno a la democracia yo la veo bien vos como la vez lo que me interesa es pensar qué cosas logramos y qué cosas sin embargo parecen ser un bulímita no si puedo citar a raúl alfonsín con la democracia se come y con la democracia se educca no se con la democracia somos un montón de cosas buenas pero hay ciertas cosas que no parece que logramos poder hacer buen punto de comienzo si tengo de sientetillarlo diré que la democracia evita que nos matemos pero no garantiza que vibamos bien y esto lo que tenemos después de cuanto vamos treinta y ocho años treinta ocho años en que dejamo de matarnos por razones políticas y no solamente esto quiero ir un poco más allá porque la socie argentina sigue siendo una de las menos violentas de la región así que la pacificación en argentina de fue cincuenta y tres años de penduros cídico militar no es solamente política está también social aunque haya un nivel de asalto superior a la media medio de asesinatos es que inferior de la media mediaclatil tan lejos desde el paraíso pero tal hijo también es el colombia méxico o brasil donde vivir es mucho más complica pero cuartifico por ciento de pobres sesti cinco por ciento de pobreza infantil eso es inaceptable es culpa a la democracia pues es a pesar de la democracia u qué pregunta no qué pregunta yo no creo personalmente que sea culpa de la democracia pero evidentemente la democracia no ha podido generar los acuerdos las instituciones o también los conflictos no al cual me acuerdo una frase de marcelo cabaroó sí que desea que la democracia argentina es el oche en muchos aspectos tenía demasiado poco conflicto en qué sentido lo digo en el sentido en que temas redistributivos temas de política económica temas por ejemplo referidos al sistema impositivo fiscal no son habituales en el congreso no de manera abierta de manera que permita discutir estos temas sino no que se dan por ahí en otras en otras instancias en la calle en salones en donde negocian personas que no están en que no lo hacen en un ámbito público  yover que tira con un típico dilema del prisionero con es el problema la hiperacionalidad individual donde cada sector prosiguiendo sus intereses particulares el judíchend se escoju en la teoría de este teorioo juego y sito se resuelve con monitoreo y con reiteración que decir cada sabe lo que está siendo lo demás tiene información y además sabe que va a seguir jundo con el otro que si traicionadas que si lo joro vas ahora te van a florr en la próxima juga si hay más sola jugada la estrategia dominante es jorobar al otro porque ese sumachero lo que gana vos es poco que lo quiere el otro y viversa si v te deja ganar no ten salida y estámosolviendo esto lo interesante es que hay un sistema en argentina que toma decisiones y a veces por consenso por ejemplo ley de góndolas por ejemplo la ley son una fría o la vida de aquileros hay grandes visciiones que están por consenso y ese concienso es digamos destructivo es tóxico esa visión contenido esas adiciones por consenso son negativas para las partes y para el todo ten perjudicando todo lo demás he tono que lo que me sorprende no tanto que falten los acuerdos sino que sus acuerdos sean destructivos tenemos una gran capacidad para ponernos de acuerdo en hacernos mal sí y al mismo tiempo esté más que nunca los que nunca se pueden poner en discusión no o sea ley de co participación la co participación tuvo un momento en el cual se puso en la gerna pública en la reforma constitucional después que es un tema intocable temas que tienen que ver con digo usted pensando propiedad de la tierra que pensando en mayores impuestos lo que se paga en argentina de impuestos en la tierra es pajísimo hay temas que tienen que ver con lo económico que están imposibilitados de ser discutido aunque parece y sorprendentemente hay un gran acuerdo que pende sobre ellos que es la constitución nacional en la constitución nacional dice que la co partiticipación había que rediscutirlas también no un cuarto de siglos durimos sin cumpliendo la constitución lo mismo a la forma elegir diputados y cuarenta años que legimo diputado le de la dictadura y senso humildociones oche o el juicio por jurados o la distribución de la propiedad para los trabajadores la constitución tiene todo los avi y goye hace un siglo no estoy diciendo querigoya ha hecho un gran gobierno o mal gobierno sino que comprendcía que su programa era la constitución nacional y porque sabía que ahí había un acuerdo que había que implementar un siglo después seguimos te el acuerdo lo implementado la otra cuestión es que realmente me parece que hay un problema en argentina de actores sociales económicos y que tampoco está claro cómo se relacionan con el sistema político o sia si pensamos en entrado la función tenemos que pensar en los extraordinarios laugros políticos en su gobierno y en la crisis económica tremenda en el cual su gobierno terminó no sea eso fue una frustración muy importante el temas que en la agentina y sectores económicos que ganan en las crisis en la crisis es un mecanismo de acumulación económica y también política no se una manera de en usted diciendo que sea una cuestión conspirativa simplemente es una noción objetiva que de cada una de las crisis en las cuales ha tenido cíclicas a quince once quince catorce años que ha tenidodo la depreza argentina hay sectores que ganan durante la estabilidad y ganan durante la durante la crisis porque pueden sacar dolorlares afuera porque pueden condicionar a los nuevos gobiernos que lo que pasó en el también entonces es muy difícil evitar las crisis cuando para actores poderosos concentrados esas crisis no son necesariamente algo malo no sino que son hoyganismo de toma de ganancia estoy de acuerdo pero tebe ir algo antipático de famosa discusión entre alfonsiínioo baldine cuando alfonsí le decía si usted es pino melarial do entra la inflación y valdir le dice así pero lo menos se daría al me lo han agradecer a mí y la inflación va seculpa a usted los sectores que se beneficio de las crisis son muchos y algunos de ellos a veces parecen prededores pero si quienche mendis estudiido de esta recompensa son los perdedores el gran ajuste y beemista fue acosto lo que salieron del meca colabor el formal porque a los indidicatos los protejeron y mucho con las obras sociales ponganía los sesenta también proteger los indica allíguet no estoy diciendo que los indidicatos seten al mismo nivel de la patria financiera usted diciendo que son muchos los sectores que tienen un pequeño beneficio y ejemplo esto va más allá de las crisis que tenemos en argentina está destruyendo la fiscalidad los subidios de la energía la tarifas baratos estos supciooss por supuesto que benefician los pobres pero son sucios pero rico y esto lo dijo martín guzmán no elcho llevar y por rico significa que la mayor masa de sus chirios va para lo que pueden pagar una tarifa como la que corresponde del costo del servicio que está lleno el esector cree benefician los pobres benefin por tus inffluxidios y lo rico también todos tratanos sacar provecho de nuevo es un dilema de hiper racionalidad individual porque acá no hay perdedores obvios si ver peres obvios harían la revolución acá los frágiles también se benefician un poquito de este desastre es argentina pero nuevo y desastre económico porque que rescatar que hace treiti ocho años que no nos matamos de morivo de ambos estoy exagerando hay otro que tan pierna en la ameérica latina pero es un país pacífico y la pregunta que vienes hasta cuándo puede durar esto una economía que no recupera sí bueno esa es una pregunta no sin embargo en la verdad y hay hay elementos que no puede decir que son rigoos han aparecido discursos ni una derecha mucho más radical de lo que pasó antes hace poco circularon unas fotos de uno en los pomos ser referentes mediáticos del de esta especie derecha que le dicen libertaria aunque yo no creo lo sea por primera vez posando con un arma como es la derecha a este salón que nunca existió en la cultura política en la argentina de los chi detra para acá no a la reivindicación pública de las armas un tema puntual pero sin tema que era un consenso que ahora parece estar rompiéndose patricia a buen riquijo también que quería añar hace unos años que los ciudadanos podían estar armados esa esa algo bastante novedosa sin embargo también es cierto que en los últimos años si una novela re las reacciones de la sociedad siguen apareciendo me parece a mí un una sociedad que tiene ciertos consensos aunque tiene ciertos principios en función de de la paz no no me queda tan claro que esas conductas lo menos soy estén premiadas necesariamente políticamente estoy de acuerdo si v mira lo concienso básico de la sociedad envocimientos supers son supesaludables su argentina es antiaarma y probacuda este un término comparado por otros países asimilable entina parangolables y esto no parece estar cambiando al contrario si destaco mirar no lo que anda con armas y va los liberaotes que entraron ahora en el congreso en la legislatura y son todo perro chico o las los tanto viendo cuúpideres impresionante no me saludaron oírir a la espalda pido disculpas a fe de alguien aunque se no disculpa incompleta por lo menos hay nuevas hay vergüenza hay vergüenza por lo que quisieron por lo que dijeron antes cuando pensaban que no están bien dob solamente por la clak portivo que los aplaudi la democracia agenquina sigue siendo super suavizadora supesuaviszaadora lo que no es esa alimentadora bueno acá tal vez haya que conversar con los los y las colegas economistas no los y las politona pusimos un montón de cosas reflexiones sobre la mesa en nuestros cuarenta años y más o menos po decir algunas cosas se construyeron la verdad que a mí a veces me llama la atención que halla tanto desconcierto acerca de que es lo que tiene que hacer argentina económicamente sí y béjame tenerer alguna nota de recuerdos al discurso de este bambburrich porque me parece importante lo que él destacó sobre los acuerdos que hacen falta quizo sin contrapución los acuerdos que conseguimos los pequenitos acues quescimos son tóxicos y esto que referente los grandes acuerros están bien la socia argentina democrática y santiarme y es provacuno los pequeños acueros están mal son de reparto de quintas este hamb buuch se puso por encima y y tenía con qué y esto lo recibieron bien de uno veía las redes túter v conocéis no se podía creer en algunos casos los elogios cavía de los dos laos y esto fue un momento momento tranquilidad que nos permitió pensar si no podríamos recuperarlos con más frecuencia no sé qué impacto te hizo v y ese discurso me parece que era era más constructiva te prorovecha una desgracia sí no sin duda esa fue una una imagen muy movilizadora lo que sucedió en el senado veremos que esto se continúe no que no sea un paréntesis que no sea un par de semanas y que después se devuelva a una situación de noce des legítimación del adversario déjame soñar bueno pero bueno terminemos la verdad que este es un díapa yo creo que cada generación queda muy marcada por el recorrido que hizo cuando entró la a la política no no necesariamente la militancia cuando sé se dio cuenta de que había algo así como en la política y sin duda el fue el evento que marcó nuestro ingreso ah a la política ya tenía diez años mi mi viejo me llevó a los actos de de sierre de lo sabmente vimos encierre mis viejos no votaron al foní mataron al lende pero muy emocionados viendo en cierra de campaña muy emocionados viéndola todo todo el convo fulporahore no de la música la estéficana o bien el juicio a las juntas ojalá por los cuarenta años el diciembre la democracia de mal de past traiga des arullo por lo no hay conciencia el castarón lo trajo y el diagnóstico es el principio laslusión bueno nos vemos dentro de quince días andrés te mando un beso me beso chao']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_DPFoCSEuA2U"
   },
   "source": [
    "-----\n",
    "The model did fairly well, considering it wasn't trained on any corpus with technical terms (the train corpus is only publically available speech datasets). Furthermore, the ground truth preprocessing is not sufficient in some cases, but for a demonstration it's a reasonable effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_lsxi5iw59m"
   },
   "source": [
    "# [Extra] Seeking the upper limit of audio sequence length\n",
    "\n",
    "So we were able to transcribe a nearly 40 minute podcast and obtain a moderately accurate transcript. While this was great for a first effort, this raises the question - \n",
    "\n",
    "**Given 16 GB of memory on a GPU, what is the upper bound of audio duration that can be transcribed by a Citrinet model in a single forward pass?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "gg0YNG9Fb_D4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original audio duration : 0:12:36.459687\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import datetime\n",
    "import math\n",
    "import gc\n",
    "\n",
    "original_duration = librosa.get_duration(filename=audio_path)\n",
    "print(\"Original audio duration :\", datetime.timedelta(seconds=original_duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJEPXWANvudq"
   },
   "source": [
    "In order to extend the audio duration, we will concatenate the same audio clip multiple times, and then trim off any excess duration from the clip as needed.\n",
    "\n",
    "For convenience, we provide a scalar multiplier to the original audio duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "8s9MHlpXyJFC"
   },
   "outputs": [],
   "source": [
    "# concatenate the file multiple times\n",
    "NUM_REPEATS = 3.5\n",
    "new_duration = original_duration * NUM_REPEATS\n",
    "\n",
    "# write a temp file\n",
    "with open('audio_repeat.txt', 'w') as f:\n",
    "    for _ in range(int(math.ceil(NUM_REPEATS))):\n",
    "        f.write(f\"file {audio_path}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-niWHB0xzfZb"
   },
   "source": [
    "Duplicate the audio several times, then trim off the required duration from the concatenated audio clip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "RIAZCKh9zY0B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.4.0 (GCC)\n",
      "  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1636205340875/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1636205340875/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-demuxer=dash --enable-gnutls --enable-gpl --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-vaapi --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-libvpx --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1636205340875/_build_env/bin/pkg-config\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
      "\u001b[0mInput #0, concat, from 'audio_repeat.txt':\n",
      "  Duration: N/A, start: 0.000000, bitrate: 256 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "Output #0, wav, to 'data/processed/concatenated_audio.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf58.76.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "size=   82738kB time=00:44:07.49 bitrate= 256.0kbits/s speed=1.48e+04x    \n",
      "video:0kB audio:82738kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000092%\n",
      "Finished repeating audio file!\n"
     ]
    }
   ],
   "source": [
    "repeated_audio_path = \"data/processed/concatenated_audio.wav\"\n",
    "\n",
    "!ffmpeg -t {new_duration} -f concat -i audio_repeat.txt -c copy -t {new_duration} {repeated_audio_path} -y\n",
    "print(\"Finished repeating audio file!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "cjBkE3M20OJR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original audio duration : 0:12:36.459687\n",
      "Repeated audio duration : 0:44:07.619062\n"
     ]
    }
   ],
   "source": [
    "original_duration = librosa.get_duration(filename=audio_path)\n",
    "repeated_duration = librosa.get_duration(filename=repeated_audio_path)\n",
    "\n",
    "print(\"Original audio duration :\", datetime.timedelta(seconds=original_duration))\n",
    "print(\"Repeated audio duration :\", datetime.timedelta(seconds=repeated_duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfIWxZ0y0hUP"
   },
   "source": [
    "Attempt to transcribe it (Note this may OOM!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "U3uweQm95y44"
   },
   "outputs": [],
   "source": [
    "# Clear up memory\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'  # You can transcribe even longer samples on the CPU, though it will take much longer !\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "r39TLjDX0bVF"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d1c212da1b463e8347a8b7d85eccfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.16 s, sys: 1.47 s, total: 3.62 s\n",
      "Wall time: 3.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with autocast():\n",
    "    transcript_repeated = model.transcribe([repeated_audio_path], batch_size=1)[0]\n",
    "    del transcript_repeated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSmes0rMwZpN"
   },
   "source": [
    "Given a large amount of GPU memory, the Citrinet model can efficiently transcribe long audio segments with ease, without the need for streaming inference.\n",
    "\n",
    "This is possible due to a simple reason - no attention mechanism is used, and Squeeze-and-Excitation mechanism does not require quadratic memory requirements yet still provides reasonable global context information."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Long-audio-transcription-Citrinet.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
