{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1c77592-6089-4784-882d-9d580cf17cb7",
   "metadata": {},
   "source": [
    "# Long Audio Transcription\n",
    "Source: https://github.com/machinelearnear/long-audio-transcription-spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1550f7bf-f574-4cff-805e-12b2cfe3f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from os.path import exists as path_exists\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea02b3ec-2529-4ad5-bd48-020adbef5d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path_exists('transcripts'):\n",
    "    !mkdir transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec17367-9c61-41ab-9673-a7c7e9ffb1ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "##Â Download audio from YouTube video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e75937b-3932-40d7-911c-270a02ef1815",
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeID = 'gFFLJaQbLCM' \n",
    "OutputFile = 'test_audio_youtube.m4a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b44aa6-d803-4b6c-9b67-ca93c03a453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path_exists(OutputFile):\n",
    "    !youtube-dl -o $OutputFile $YouTubeID --extract-audio --restrict-filenames -f 'bestaudio[ext=m4a]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5e10fc-68b7-4a3f-b8fc-5bd38874594c",
   "metadata": {},
   "source": [
    "## End to End Automatic Speech Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2717b5d-46fa-4493-a7f7-d214666db611",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"jonatasgrosman/wav2vec2-xls-r-1b-spanish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4880622-2cdc-4a11-8a3f-f250808bb6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(transcript, text=None):\n",
    "    with open(f'transcripts/transcribed_speech_{text}.txt', \"w\") as f:\n",
    "        f.write(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7331b8-4f19-4627-8d7e-9a66f532bd5d",
   "metadata": {},
   "source": [
    "### Option A: Process long audio file directly with `Pipelines`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa414299-bac3-4145-9e6c-891aabe2317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3ced5c-49ca-477a-a7df-f3e12c516d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da12838-4eb6-4d05-b5a5-587b36514acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stime = time.time()\n",
    "# transcript = pipe(OutputFile, chunk_length_s=10, stride_length_s=(4,2))\n",
    "print(f'total time: {time.time()-stime:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3511adb2-150a-4117-880e-dcf309741591",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transcript)\n",
    "save_to_file(transcript,text='hf_pipelines')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825998b5-a93b-4fba-9214-1270f207cbd0",
   "metadata": {},
   "source": [
    "### Option B: Split audio files in chunks by timestamp (`PyDub`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ee7770-f2ad-4f67-a80d-00d4cff2cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pydub\n",
    "import array\n",
    "import numpy as np\n",
    "from pydub.utils import mediainfo\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import get_array_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbe88fb-990e-4da0-b94f-f48aee840e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pydub_speech = pydub.AudioSegment.from_file(OutputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136db606-ef2a-4b60-981b-2b3019a7d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "pydub_speech[:15*1000] # miliseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46cbe8d-32b8-4182-938a-23ebc0857069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_resampler(sound, sample_rate=16000):\n",
    "    sound = sound.set_frame_rate(sample_rate)\n",
    "    left = sound.split_to_mono()[0]\n",
    "    bit_depth = left.sample_width * 8\n",
    "    array_type = pydub.utils.get_array_type(bit_depth)\n",
    "    numeric_array = np.array(array.array(array_type, left._data))\n",
    "    \n",
    "    return np.asarray(numeric_array,dtype=np.double), sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34010772-b2f8-471c-9afd-334de13ad552",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech, sample_rate = audio_resampler(pydub_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2013f4bf-d045-4c9f-b4c3-d5972575532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = ''\n",
    "for chunk in np.array_split(speech,len(speech)/sample_rate/30)[:2]: # split every 30 seconds\n",
    "    output = pipe(chunk)\n",
    "    transcript = transcript + ' ' + output['text']\n",
    "    print(output)\n",
    "    \n",
    "transcript = transcript.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e395c0e-ca48-4124-b46c-4db0c81e0338",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transcript)\n",
    "save_to_file(transcript,text='pydub_timestamps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fe66eb-7761-481b-a669-bd78c91bca80",
   "metadata": {},
   "source": [
    "### Option C: Split audio files based on silence detection (`Librosa`/`PyDub`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5875256-4891-4f8f-9dd4-081662e05e57",
   "metadata": {},
   "source": [
    "(1) `Librosa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaccfee9-e88b-4cb7-8343-cec3aae502dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from librosa import display\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b43ce4-a774-4a27-8380-963b7ae4b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech, sample_rate = librosa.load(OutputFile,sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4727d7-6177-45ff-91e7-5ed817dd0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "librosa.display.waveshow(y=speech[:30*sample_rate], sr=sample_rate) # first 30 seconds\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d6f75c-a103-491f-984b-e85f8ab0ab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_mute_sections_in_speech = librosa.effects.split(speech,top_db=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72082cd5-b0e3-4f75-b90b-8d1686504be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = ''\n",
    "for chunk in non_mute_sections_in_speech[:6]:\n",
    "    speech_chunk = speech[chunk[0]:chunk[1]]\n",
    "    output = pipe(speech_chunk)\n",
    "    transcript = transcript + ' ' + output['text']\n",
    "    print(output)\n",
    "    \n",
    "transcript = transcript.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75da98c-0b57-4637-9c5b-cdcc2d1d5189",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transcript)\n",
    "save_to_file(transcript,text='librosa_silence')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e6a333-9ab7-4873-86c7-daf856a5fc46",
   "metadata": {},
   "source": [
    "(2) `PyDub`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1d0bbb-97c1-4f5a-9259-8212a7a63ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pydub_speech = pydub.AudioSegment.from_file(OutputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a0ecaf-a076-4034-9fdf-d793c411e306",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = pydub.silence.split_on_silence(\n",
    "    pydub_speech,\n",
    "    min_silence_len = 500,\n",
    "    silence_thresh = pydub_speech.dBFS - 16,\n",
    "    keep_silence = 250, # optional\n",
    ")\n",
    "\n",
    "# minimum chunk length\n",
    "target_length = 20 * 1000 # 20 seconds\n",
    "\n",
    "output_chunks = [chunks[0]]\n",
    "for chunk in chunks[1:]:\n",
    "    if len(output_chunks[-1]) < target_length:\n",
    "        output_chunks[-1] += chunk\n",
    "    else:\n",
    "        # if the last output chunk\n",
    "        # is longer than the target length,\n",
    "        # we can start a new one\n",
    "        output_chunks.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd092c94-9b34-488b-ab21-acdc9835f955",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d76b46-ae8d-420f-aacf-039dd5707473",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = ''\n",
    "for chunk in output_chunks[:6]:\n",
    "    speech_chunk, sample_rate = audio_resampler(chunk)\n",
    "    output = pipe(speech_chunk)\n",
    "    transcript = transcript + ' ' + output['text']\n",
    "    print(output)\n",
    "    \n",
    "transcript = transcript.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd5e429-46b7-457a-8300-c81b1c06615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transcript)\n",
    "save_to_file(transcript,text='pydub_silence')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975e4951-9576-4180-9c2b-055642b50ec9",
   "metadata": {},
   "source": [
    "## Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "339df000-dff6-4ec6-b13b-1af7f52686d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84b2a239-e5b8-4eae-b72e-f989f5cebe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"transcripts/transcribed_speech_hf_pipelines.txt\"\n",
    "compare = \"transcripts/transcribed_speech_pydub_timestamps.txt\"\n",
    "# compare = \"transcripts/transcribed_speech_pydub_silence.txt\"\n",
    "# compare = \"transcripts/transcribed_speech_librosa_silence.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f15fa9bb-2607-4f58-b058-aed16c41157b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: transcripts/transcribed_speech_pydub_silence.txt / Compare: transcripts/transcribed_speech_pydub_timestamps.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: grid;grid-template-columns: 1fr 1fr;grid-gap: 20px;\"><p></p><p></p><p>soy marÃ­a esperanza caso soy andrÃ©s malamud y esto es ahora un podcast de conversaciÃ³n polÃ­tica de el diario aholandrÃ©s cÃ³mo estÃ¡s buen dÃ­a buen dÃ­a me comandaos creo que estÃ¡s viajando sospecha exactamente hacia argentina cuando estemos en el aire voy a estar en la patria buenÃ­simo bueno y de quÃ© vamos holaestasemana saliÃ³ el tema de los ex presidentes que podrÃ­an ser candidatos quÃ© te parece vale esto ay que marcarlo en una cuestiÃ³n legal o sea en el sentido de que en argentina se da la caracterÃ­stica de que los ex presidentes legalmente pueden volver a ser presidentes y hay no sÃ© si un montÃ³n pero hay varios casos histÃ³ricos empezando por los mÃ¡s famosos julio argentino roca domingo perÃ³n lo que sÃ­ creo que es novedoso es que en este momento actual se da la circunstancia de que tenemos dos expresidentes activos en polÃ­tica exactamente te agrego irigosiom para que mi banda nos enojepor la comisiÃ³n rrosectamente asÃ­ mÃ¡s allÃ¡ de las reelecciones inmediatas que estaban permitidas en los</p><p>soy marÃ­a esperanza caso soy andrÃ©s malamud y esto es ahora un podcast de conversaciÃ³n polÃ­tica de el diario aholandrÃ©s cÃ³mo estÃ¡s buen dÃ­a buen dÃ­a me comandaos creo que estÃ¡s viajando sospecha exactamente hacia argentina cuando estemos en el aire voy a estar en la patria buenÃ­simo bueno y de quÃ© vamos holaestasemana saliÃ³ el tema de los ex presidentes que podrÃ­an ser candidatos quÃ© te parece vale esto ay que marcarlo en una cuestiÃ³n legal o sea en el sentido de que en argentina se da la caracterÃ­stica de que los ex presidentes legalmente pueden volver a ser presidentes y hay no sÃ© si un montÃ³n pero hay varios casos histÃ³ricos empezando por los mÃ¡s famosos julio argentino roca domingo perÃ³n lo que sÃ­ creo que es novedoso es que en este momento actual se da la circunstancia de que tenemos dos expresidentes activos en polÃ­tica exactamente te agrego irigosiom para que mi banda nos enojepor la comisiÃ³n rrosectamente asÃ­ mÃ¡s allÃ¡ de las reelecciones inmediatas que estaban permitidas en los <span style=\"background: #FF6502;\">cincuenta y despuÃ©s no y otra vez a partir del noventa y cuatro los expresidentes pueden volver dejando pasar un mandato despuÃ©s del segundo y ahora tanto macri como cristina estÃ¡n en condiciones y muchos habÃ­an pensado que o no querÃ­an o no podÃ­an y ahora de repente algunos salieron a pensar y carlos paÃ±ete mÃ¡s explÃ­cito que los dos quieren y que los dos pueden aunque esto segundo estÃ¡ mÃ¡s en duda bueno hay varias cuestiones para desmenuzar acÃ¡ la primera empecemos por lo de pueden y esto me parece muy interesante porque en muchos muchos aspectos a mÃ­ me parece no sÃ© quÃ© pensÃ¡s vos que realmente estamos en un momento en el cual las posiciones y yo te dirÃ­a mÃ¡s hasta los discursos en muchos sentidos de cristina france kirchner y de mauricio macri con respecto a sus propios espacios estÃ¡n muy en espejo y una de las cosas que estÃ¡n en espejo es que cuando tanto cristina franz de garner dejÃ³ su mandato en el y cuando mauricio macri dejÃ³ su mandato en el iecueparecÃ­a que estaba muy seguro de que ambos expresidentes tenÃ­an un nÃºcleo de apoyo pero que no podÃ­an volver a ser presidente no sea la famosa frase de dejarme que organice mi percepciÃ³n espacial de que tenÃ­an el piso alto pero el techo bajo noexec</span></p></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = open(base,'r').readlines()[0][:1000]\n",
    "b = open(compare_to,'r').readlines()[0]\n",
    "print(f'Original: {base} / Compare: {compare}')\n",
    "display(HTML(html_diffs(a,b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfccbe7-e7fa-4cb8-ac00-1e3e01122399",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d500173-0460-445e-8ebc-bc395c9f5d02",
   "metadata": {},
   "source": [
    "- [Making automatic speech recognition work on large files with Wav2Vec2 in Transformers](https://huggingface.co/blog/asr-chunking)\n",
    "- [Boosting Wav2Vec2 with n-grams in Transformers](https://huggingface.co/blog/wav2vec2-with-ngram)\n",
    "- https://huggingface.co/jonatasgrosman/wav2vec2-xls-r-1b-spanish\n",
    "- https://huggingface.co/jonatasgrosman/wav2vec2-large-xlsr-53-spanish\n",
    "- https://huggingface.co/spaces/speech-recognition-community-v2/FinalLeaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae243f7a-612e-4ce8-ae69-0267e28d9b26",
   "metadata": {},
   "source": [
    "### Option D: Stream audio using `Librosa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c834f2c6-d4ef-4581-b931-4204d8074adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# def correct_sentence(input_text):\n",
    "#     sentences = nltk.sent_tokenize(input_text)\n",
    "#     return (' '.join([s.replace(s[0],s[0].capitalize(),1) for s in sentences]))\n",
    "\n",
    "# def asr_transcript(tokenizer, model, input_file):\n",
    "#     transcript = \"\"\n",
    "#     # Ensure that the sample rate is 16k\n",
    "#     print(librosa.get_samplerate(input_file))\n",
    "\n",
    "#     # Stream over 30 seconds chunks rather than load the full file\n",
    "#     stream = librosa.stream(\n",
    "#         input_file,\n",
    "#         block_length=30,\n",
    "#         frame_length=16000,\n",
    "#         hop_length=16000\n",
    "#     )\n",
    "\n",
    "#     for speech in stream:\n",
    "#         if len(speech.shape) > 1:\n",
    "#             speech = speech[:, 0] + speech[:, 1]\n",
    "\n",
    "#         input_values = tokenizer(speech, return_tensors=\"pt\").input_values\n",
    "#         logits = model(input_values).logits\n",
    "\n",
    "#         predicted_ids = torch.argmax(logits, dim=-1)\n",
    "#         transcription = tokenizer.decode(predicted_ids[0])\n",
    "#         transcript += correct_sentence(transcription.lower())\n",
    "\n",
    "#     return transcript"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearnear-long-audio-transcription:Python",
   "language": "python",
   "name": "conda-env-machinelearnear-long-audio-transcription-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
