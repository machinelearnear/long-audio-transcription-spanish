{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1c77592-6089-4784-882d-9d580cf17cb7",
   "metadata": {},
   "source": [
    "# Long Audio Transcription\n",
    "Source: https://github.com/machinelearnear/long-audio-transcription-spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1550f7bf-f574-4cff-805e-12b2cfe3f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from os.path import exists as path_exists\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea02b3ec-2529-4ad5-bd48-020adbef5d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path_exists('transcripts'):\n",
    "    !mkdir transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec17367-9c61-41ab-9673-a7c7e9ffb1ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download audio from YouTube video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e75937b-3932-40d7-911c-270a02ef1815",
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeID = 'gFFLJaQbLCM' \n",
    "OutputFile = 'test_audio_youtube.m4a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b44aa6-d803-4b6c-9b67-ca93c03a453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path_exists(OutputFile):\n",
    "    !youtube-dl -o $OutputFile $YouTubeID --extract-audio --restrict-filenames -f 'bestaudio[ext=m4a]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5e10fc-68b7-4a3f-b8fc-5bd38874594c",
   "metadata": {},
   "source": [
    "## End to End Automatic Speech Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2717b5d-46fa-4493-a7f7-d214666db611",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"jonatasgrosman/wav2vec2-xls-r-1b-spanish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4880622-2cdc-4a11-8a3f-f250808bb6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(transcript, text=None):\n",
    "    with open(f'transcripts/transcribed_speech_{text}.txt', \"w\") as f:\n",
    "        f.write(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7331b8-4f19-4627-8d7e-9a66f532bd5d",
   "metadata": {},
   "source": [
    "### Option A: Process long audio file directly with `Pipelines`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa414299-bac3-4145-9e6c-891aabe2317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3ced5c-49ca-477a-a7df-f3e12c516d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da12838-4eb6-4d05-b5a5-587b36514acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stime = time.time()\n",
    "# transcript = pipe(OutputFile, chunk_length_s=10, stride_length_s=(4,2))\n",
    "print(f'total time: {time.time()-stime:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3511adb2-150a-4117-880e-dcf309741591",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transcript)\n",
    "save_to_file(transcript,text='hf_pipelines')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825998b5-a93b-4fba-9214-1270f207cbd0",
   "metadata": {},
   "source": [
    "### Option B: Split audio files in chunks by timestamp (`PyDub`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ee7770-f2ad-4f67-a80d-00d4cff2cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pydub\n",
    "import array\n",
    "import numpy as np\n",
    "from pydub.utils import mediainfo\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import get_array_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbe88fb-990e-4da0-b94f-f48aee840e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pydub_speech = pydub.AudioSegment.from_file(OutputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136db606-ef2a-4b60-981b-2b3019a7d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "pydub_speech[:15*1000] # miliseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46cbe8d-32b8-4182-938a-23ebc0857069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_resampler(sound, sample_rate=16000):\n",
    "    sound = sound.set_frame_rate(sample_rate)\n",
    "    left = sound.split_to_mono()[0]\n",
    "    bit_depth = left.sample_width * 8\n",
    "    array_type = pydub.utils.get_array_type(bit_depth)\n",
    "    numeric_array = np.array(array.array(array_type, left._data))\n",
    "    \n",
    "    return np.asarray(numeric_array,dtype=np.double), sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34010772-b2f8-471c-9afd-334de13ad552",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech, sample_rate = audio_resampler(pydub_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2013f4bf-d045-4c9f-b4c3-d5972575532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = ''\n",
    "for chunk in np.array_split(speech,len(speech)/sample_rate/30)[:2]: # split every 30 seconds\n",
    "    output = pipe(chunk)\n",
    "    transcript = transcript + ' ' + output['text']\n",
    "    print(output)\n",
    "    \n",
    "transcript = transcript.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e395c0e-ca48-4124-b46c-4db0c81e0338",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transcript)\n",
    "save_to_file(transcript,text='pydub_timestamps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fe66eb-7761-481b-a669-bd78c91bca80",
   "metadata": {},
   "source": [
    "### Option C: Split audio files based on silence detection (`Librosa`/`PyDub`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5875256-4891-4f8f-9dd4-081662e05e57",
   "metadata": {},
   "source": [
    "(1) `Librosa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaccfee9-e88b-4cb7-8343-cec3aae502dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from librosa import display\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b43ce4-a774-4a27-8380-963b7ae4b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech, sample_rate = librosa.load(OutputFile,sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4727d7-6177-45ff-91e7-5ed817dd0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "librosa.display.waveshow(y=speech[:30*sample_rate], sr=sample_rate) # first 30 seconds\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d6f75c-a103-491f-984b-e85f8ab0ab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_mute_sections_in_speech = librosa.effects.split(speech,top_db=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72082cd5-b0e3-4f75-b90b-8d1686504be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = ''\n",
    "for chunk in non_mute_sections_in_speech[:6]:\n",
    "    speech_chunk = speech[chunk[0]:chunk[1]]\n",
    "    output = pipe(speech_chunk)\n",
    "    transcript = transcript + ' ' + output['text']\n",
    "    print(output)\n",
    "    \n",
    "transcript = transcript.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75da98c-0b57-4637-9c5b-cdcc2d1d5189",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transcript)\n",
    "save_to_file(transcript,text='librosa_silence')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e6a333-9ab7-4873-86c7-daf856a5fc46",
   "metadata": {},
   "source": [
    "(2) `PyDub`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1d0bbb-97c1-4f5a-9259-8212a7a63ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pydub_speech = pydub.AudioSegment.from_file(OutputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a0ecaf-a076-4034-9fdf-d793c411e306",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = pydub.silence.split_on_silence(\n",
    "    pydub_speech,\n",
    "    min_silence_len = 500,\n",
    "    silence_thresh = pydub_speech.dBFS - 16,\n",
    "    keep_silence = 250, # optional\n",
    ")\n",
    "\n",
    "# minimum chunk length\n",
    "target_length = 20 * 1000 # 20 seconds\n",
    "\n",
    "output_chunks = [chunks[0]]\n",
    "for chunk in chunks[1:]:\n",
    "    if len(output_chunks[-1]) < target_length:\n",
    "        output_chunks[-1] += chunk\n",
    "    else:\n",
    "        # if the last output chunk\n",
    "        # is longer than the target length,\n",
    "        # we can start a new one\n",
    "        output_chunks.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd092c94-9b34-488b-ab21-acdc9835f955",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d76b46-ae8d-420f-aacf-039dd5707473",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = ''\n",
    "for chunk in output_chunks[:6]:\n",
    "    speech_chunk, sample_rate = audio_resampler(chunk)\n",
    "    output = pipe(speech_chunk)\n",
    "    transcript = transcript + ' ' + output['text']\n",
    "    print(output)\n",
    "    \n",
    "transcript = transcript.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd5e429-46b7-457a-8300-c81b1c06615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transcript)\n",
    "save_to_file(transcript,text='pydub_silence')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975e4951-9576-4180-9c2b-055642b50ec9",
   "metadata": {},
   "source": [
    "## Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "339df000-dff6-4ec6-b13b-1af7f52686d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84b2a239-e5b8-4eae-b72e-f989f5cebe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"transcripts/transcribed_speech_hf_pipelines.txt\"\n",
    "compare = \"transcripts/transcribed_speech_pydub_timestamps.txt\"\n",
    "# compare = \"transcripts/transcribed_speech_pydub_silence.txt\"\n",
    "# compare = \"transcripts/transcribed_speech_librosa_silence.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f15fa9bb-2607-4f58-b058-aed16c41157b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: transcripts/transcribed_speech_pydub_silence.txt / Compare: transcripts/transcribed_speech_pydub_timestamps.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: grid;grid-template-columns: 1fr 1fr;grid-gap: 20px;\"><p></p><p></p><p>soy maría esperanza caso soy andrés malamud y esto es ahora un podcast de conversación política de el diario aholandrés cómo estás buen día buen día me comandaos creo que estás viajando sospecha exactamente hacia argentina cuando estemos en el aire voy a estar en la patria buenísimo bueno y de qué vamos holaestasemana salió el tema de los ex presidentes que podrían ser candidatos qué te parece vale esto ay que marcarlo en una cuestión legal o sea en el sentido de que en argentina se da la característica de que los ex presidentes legalmente pueden volver a ser presidentes y hay no sé si un montón pero hay varios casos históricos empezando por los más famosos julio argentino roca domingo perón lo que sí creo que es novedoso es que en este momento actual se da la circunstancia de que tenemos dos expresidentes activos en política exactamente te agrego irigosiom para que mi banda nos enojepor la comisión rrosectamente así más allá de las reelecciones inmediatas que estaban permitidas en los</p><p>soy maría esperanza caso soy andrés malamud y esto es ahora un podcast de conversación política de el diario aholandrés cómo estás buen día buen día me comandaos creo que estás viajando sospecha exactamente hacia argentina cuando estemos en el aire voy a estar en la patria buenísimo bueno y de qué vamos holaestasemana salió el tema de los ex presidentes que podrían ser candidatos qué te parece vale esto ay que marcarlo en una cuestión legal o sea en el sentido de que en argentina se da la característica de que los ex presidentes legalmente pueden volver a ser presidentes y hay no sé si un montón pero hay varios casos históricos empezando por los más famosos julio argentino roca domingo perón lo que sí creo que es novedoso es que en este momento actual se da la circunstancia de que tenemos dos expresidentes activos en política exactamente te agrego irigosiom para que mi banda nos enojepor la comisión rrosectamente así más allá de las reelecciones inmediatas que estaban permitidas en los <span style=\"background: #FF6502;\">cincuenta y después no y otra vez a partir del noventa y cuatro los expresidentes pueden volver dejando pasar un mandato después del segundo y ahora tanto macri como cristina están en condiciones y muchos habían pensado que o no querían o no podían y ahora de repente algunos salieron a pensar y carlos pañete más explícito que los dos quieren y que los dos pueden aunque esto segundo está más en duda bueno hay varias cuestiones para desmenuzar acá la primera empecemos por lo de pueden y esto me parece muy interesante porque en muchos muchos aspectos a mí me parece no sé qué pensás vos que realmente estamos en un momento en el cual las posiciones y yo te diría más hasta los discursos en muchos sentidos de cristina france kirchner y de mauricio macri con respecto a sus propios espacios están muy en espejo y una de las cosas que están en espejo es que cuando tanto cristina franz de garner dejó su mandato en el y cuando mauricio macri dejó su mandato en el iecueparecía que estaba muy seguro de que ambos expresidentes tenían un núcleo de apoyo pero que no podían volver a ser presidente no sea la famosa frase de dejarme que organice mi percepción espacial de que tenían el piso alto pero el techo bajo noexec</span></p></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = open(base,'r').readlines()[0][:1000]\n",
    "b = open(compare_to,'r').readlines()[0]\n",
    "print(f'Original: {base} / Compare: {compare}')\n",
    "display(HTML(html_diffs(a,b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfccbe7-e7fa-4cb8-ac00-1e3e01122399",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d500173-0460-445e-8ebc-bc395c9f5d02",
   "metadata": {},
   "source": [
    "- [Making automatic speech recognition work on large files with Wav2Vec2 in Transformers](https://huggingface.co/blog/asr-chunking)\n",
    "- [Boosting Wav2Vec2 with n-grams in Transformers](https://huggingface.co/blog/wav2vec2-with-ngram)\n",
    "- https://huggingface.co/jonatasgrosman/wav2vec2-xls-r-1b-spanish\n",
    "- https://huggingface.co/jonatasgrosman/wav2vec2-large-xlsr-53-spanish\n",
    "- https://huggingface.co/spaces/speech-recognition-community-v2/FinalLeaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae243f7a-612e-4ce8-ae69-0267e28d9b26",
   "metadata": {},
   "source": [
    "### Option D: Stream audio using `Librosa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c834f2c6-d4ef-4581-b931-4204d8074adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# def correct_sentence(input_text):\n",
    "#     sentences = nltk.sent_tokenize(input_text)\n",
    "#     return (' '.join([s.replace(s[0],s[0].capitalize(),1) for s in sentences]))\n",
    "\n",
    "# def asr_transcript(tokenizer, model, input_file):\n",
    "#     transcript = \"\"\n",
    "#     # Ensure that the sample rate is 16k\n",
    "#     print(librosa.get_samplerate(input_file))\n",
    "\n",
    "#     # Stream over 30 seconds chunks rather than load the full file\n",
    "#     stream = librosa.stream(\n",
    "#         input_file,\n",
    "#         block_length=30,\n",
    "#         frame_length=16000,\n",
    "#         hop_length=16000\n",
    "#     )\n",
    "\n",
    "#     for speech in stream:\n",
    "#         if len(speech.shape) > 1:\n",
    "#             speech = speech[:, 0] + speech[:, 1]\n",
    "\n",
    "#         input_values = tokenizer(speech, return_tensors=\"pt\").input_values\n",
    "#         logits = model(input_values).logits\n",
    "\n",
    "#         predicted_ids = torch.argmax(logits, dim=-1)\n",
    "#         transcription = tokenizer.decode(predicted_ids[0])\n",
    "#         transcript += correct_sentence(transcription.lower())\n",
    "\n",
    "#     return transcript"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearnear-long-audio-transcription:Python",
   "language": "python",
   "name": "conda-env-machinelearnear-long-audio-transcription-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
